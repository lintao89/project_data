{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83139664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymysql, urllib.request, csv, re, datetime\n",
    "from flask import Flask, render_template, request, redirect\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from flask_cors import CORS\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "#基隆市KEL Keelung\n",
    "KEL_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%9F%BA%E9%9A%86%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#新北市NTPC New_Taipei\n",
    "NTPC_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E6%96%B0%E5%8C%97%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#台北市TPE Taipei\n",
    "TPE_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%8F%B0%E5%8C%97%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#桃園市TYN Taoyuan\n",
    "TYN_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E6%A1%83%E5%9C%92%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#新竹縣HSZ0 Hsinchu_County\n",
    "HSZ0_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E6%96%B0%E7%AB%B9%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#新竹市HSZ1 Hsinchu_City\n",
    "HSZ1_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E6%96%B0%E7%AB%B9%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#苗栗縣ZMI Miaoli\n",
    "ZMI_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E8%8B%97%E6%A0%97%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#台中市TXG Taichung\n",
    "TXG_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%8F%B0%E4%B8%AD%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#彰化縣CHW Changhua\n",
    "CHW_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%BD%B0%E5%8C%96%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#南投縣NTC Nantou\n",
    "NTC_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%8D%97%E6%8A%95%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#雲林縣YUN Yunlin\n",
    "YUN_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E9%9B%B2%E6%9E%97%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#嘉義縣CYI0 Chiayi_County\n",
    "CYI0_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%98%89%E7%BE%A9%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#嘉義市CYI1 Chiayi_City\n",
    "CYI1_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%98%89%E7%BE%A9%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#台南市TNN Tainan\n",
    "TNN_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%8F%B0%E5%8D%97%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#高雄市KHH Kaohsiung\n",
    "KHH_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E9%AB%98%E9%9B%84%E5%B8%82%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#屏東縣PIF Pingtung\n",
    "PIF_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%B1%8F%E6%9D%B1%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#宜蘭縣ILA Yilan\n",
    "ILA_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%AE%9C%E8%98%AD%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#花蓮縣HUN Hualien\n",
    "HUN_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E8%8A%B1%E8%93%AE%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#台東縣TTT Taitung\n",
    "TTT_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E5%8F%B0%E6%9D%B1%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#澎湖縣PEH Penghu\n",
    "PEH_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E6%BE%8E%E6%B9%96%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#金門縣KNH Kinmen\n",
    "KNH_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E9%87%91%E9%96%80%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "#連江縣LNN Lienchiang\n",
    "LNN_url = \"https://raw.githubusercontent.com/lintao89/project_data/main/%E9%80%A3%E6%B1%9F%E7%B8%A3%E6%AF%8F%E6%97%A5%E7%A2%BA%E8%A8%BA%E6%95%B8.csv\"\n",
    "\n",
    "def create():\n",
    "    conn = pymysql.connect(\n",
    "        host = 'localhost',\n",
    "        user = 'root',\n",
    "        password = '0000',\n",
    "        database = '專題'\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    sql_create = '''\n",
    "    CREATE TABLE IF NOT EXISTS Taiwan (\n",
    "    個案研判日 Date NULL, \n",
    "    縣市 VARCHAR(255) NULL, \n",
    "    確定病例數 VARCHAR(255) NULL);'''\n",
    "    cursor.execute(sql_create)\n",
    "    cursor.execute('truncate Taiwan;') #清空資料表\n",
    "    \n",
    "    #台中市TXG Taichung\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(TXG_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "\n",
    "    #基隆市KEL Keelung\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(KEL_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #新北市NTPC New_Taipei\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(NTPC_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #台北市TPE Taipei\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(TPE_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #桃園市TYN Taoyuan\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(TYN_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #新竹縣HSZ0 Hsinchu_County\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(HSZ0_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #新竹市HSZ1 Hsinchu_City\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(HSZ1_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #苗栗縣ZMI Miaoli\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(ZMI_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #彰化縣CHW Changhua\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(CHW_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #南投縣NTC Nantou\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(NTC_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #雲林縣YUN Yunlin\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(YUN_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #嘉義縣CYI0 Chiayi_County\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(CYI0_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #嘉義市CYI1 Chiayi_City\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(CYI1_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #台南市TNN Tainan\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(TNN_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #高雄市KHH Kaohsiung\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(KHH_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #屏東縣PIF Pingtung\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(PIF_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #宜蘭縣ILA Yilan\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(ILA_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #花蓮縣HUN Hualien\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(HUN_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #台東縣TTT Taitung\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(TTT_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #澎湖縣PEH Penghu\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(PEH_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #金門縣KNH Kinmen\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(KNH_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #連江縣LNN Lienchiang\n",
    "    sql_insert = '''insert into Taiwan value(%s, %s, %s);'''\n",
    "    with urllib.request.urlopen(LNN_url) as f:\n",
    "        f.readline().decode('UTF-8')\n",
    "        while (True):\n",
    "            res = f.readline().strip().decode(encoding='UTF-8').split(',')\n",
    "            # 到沒資料離開迴圈\n",
    "            if res != ['']:\n",
    "                cursor.execute(sql_insert,[res[0], res[1], res[2]])\n",
    "                #print(res)\n",
    "            else:\n",
    "                break\n",
    "        conn.commit()\n",
    "    \n",
    "    #cursor.close()\n",
    "    #conn.close()\n",
    "\n",
    "create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb2515",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Flask Start... ####\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.20.3:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/May/2023 10:25:44] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST\n",
      "['2021-07-15', '2021-07-16', '2021-07-17', '2021-07-18', '2021-07-19', '2021-07-20', '2021-07-21']\n",
      "<class 'list'>\n",
      "21\n",
      "[21]\n",
      "user_input： 一周 <class 'str'>\n",
      "user_date： 2021-07-15 <class 'str'>\n",
      "user_date_： 2021-07-21 <class 'str'>\n",
      "data_all_TPE： [('9',), ('13',), ('1',), ('5',), ('1',), ('7',), ('20',)] <class 'list'>\n",
      "data_re03： ['9', '13', '1', '5', '1', '7', '20'] <class 'list'>\n",
      "data_all： [21] <class 'list'>\n",
      "today_data： 21 <class 'int'>\n",
      "data_TPE： 20 <class 'str'>\n",
      "list_all： {'2021-07-15': 21} <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2023 10:25:56] \"POST /second_web HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST\n",
      "['2022-06-09', '2022-06-10', '2022-06-11', '2022-06-12', '2022-06-13', '2022-06-14', '2022-06-15']\n",
      "<class 'list'>\n",
      "68278\n",
      "52568\n",
      "77521\n",
      "45056\n",
      "66088\n",
      "68907\n",
      "63130\n",
      "[68278, 52568, 77521, 45056, 66088, 68907, 63130]\n",
      "user_input： 一周 <class 'str'>\n",
      "user_date： 2022-06-09 <class 'str'>\n",
      "user_date_： 2022-06-15 <class 'str'>\n",
      "data_all_TPE： [('4203',), ('3310',), ('4328',), ('2674',), ('3521',), ('3791',), ('3449',)] <class 'list'>\n",
      "data_re03： ['4203', '3310', '4328', '2674', '3521', '3791', '3449'] <class 'list'>\n",
      "data_all： [68278, 52568, 77521, 45056, 66088, 68907, 63130] <class 'list'>\n",
      "today_data： 63130 <class 'int'>\n",
      "data_TPE： 3449 <class 'str'>\n",
      "list_all： {'2022-06-09': 68278, '2022-06-10': 52568, '2022-06-11': 77521, '2022-06-12': 45056, '2022-06-13': 66088, '2022-06-14': 68907, '2022-06-15': 63130} <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2023 10:26:13] \"POST /second_web HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST\n",
      "['2022-06-09', '2022-06-10', '2022-06-11', '2022-06-12', '2022-06-13', '2022-06-14', '2022-06-15']\n",
      "<class 'list'>\n",
      "68278\n",
      "52568\n",
      "77521\n",
      "45056\n",
      "66088\n",
      "68907\n",
      "63130\n",
      "[68278, 52568, 77521, 45056, 66088, 68907, 63130]\n",
      "user_input： 一周 <class 'str'>\n",
      "user_date： 2022-06-09 <class 'str'>\n",
      "user_date_： 2022-06-15 <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2023 10:28:57] \"POST /second_web HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_all_TPE： [('4203',), ('3310',), ('4328',), ('2674',), ('3521',), ('3791',), ('3449',)] <class 'list'>\n",
      "data_re03： ['4203', '3310', '4328', '2674', '3521', '3791', '3449'] <class 'list'>\n",
      "data_all： [68278, 52568, 77521, 45056, 66088, 68907, 63130] <class 'list'>\n",
      "today_data： 63130 <class 'int'>\n",
      "data_TPE： 3449 <class 'str'>\n",
      "list_all： {'2022-06-09': 68278, '2022-06-10': 52568, '2022-06-11': 77521, '2022-06-12': 45056, '2022-06-13': 66088, '2022-06-14': 68907, '2022-06-15': 63130} <class 'dict'>\n",
      "1/1 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017D81460700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017D827E6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-12 10:30:41,771] ERROR in app: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Todd\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Todd\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Todd\\anaconda3\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\Todd\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Todd\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\Todd\\AppData\\Local\\Temp\\ipykernel_12988\\3992540131.py\", line 2077, in predict\n",
      "    list_all = dict(zip(date_all, data_all))\n",
      "NameError: name 'date_all' is not defined\n",
      "127.0.0.1 - - [12/May/2023 10:30:41] \"POST /predict HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "# 初始化sqlalchemy\n",
    "db = SQLAlchemy()\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS']=False\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = \"mysql+pymysql://root:0000@localhost:3306/專題\"\n",
    "# [DB_TYPE]+[DB_CONNECTOR]://[USERNAME]:[PASSWORD]@[HOST]:[PORT]/[DB_NAME]\n",
    "\n",
    "CORS(app)\n",
    "db.init_app(app)\n",
    "#db = SQLAlchemy(app)\n",
    "\n",
    "first_url = \"https://raw.githubusercontent.com/zu-z/project/main/first_web.html\"\n",
    "#\"https://htmlpreview.github.io/?https://github.com/zu-z/project/blob/main/first_web.html\"\n",
    "second_url = \"https://raw.githubusercontent.com/zu-z/project/main/second_web.html\"\n",
    "#\"https://htmlpreview.github.io/?https://github.com/zu-z/project/blob/main/second_web.html\"\n",
    "third_url = \"https://raw.githubusercontent.com/zu-z/project/main/third_web.html\"\n",
    "#\"https://htmlpreview.github.io/?https://github.com/zu-z/project/blob/main/third_web.html\"\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def first_web():\n",
    "    #with urllib.request.urlopen(first_url) as response:\n",
    "        #first = response.read()\n",
    "    #return first\n",
    "    return render_template('first_web.html')\n",
    "\n",
    "@app.route(\"/second_web\", methods=[\"POST\",\"GET\"])\n",
    "def second_web():\n",
    "    print(request.method)\n",
    "    if request.method == \"POST\":\n",
    "        user_input = request.values['user_input']\n",
    "        user_date = request.values['user_date']\n",
    "    else:\n",
    "        user_input = request.args.get('user_input')\n",
    "        user_date = request.args.get('user_date')\n",
    "    \n",
    "    date = datetime.datetime.strptime(user_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    if(user_input == '一天'):\n",
    "        user_date_ = user_date\n",
    "        date_all = []\n",
    "        date_all.append(user_date_)\n",
    "        \n",
    "        #基隆市KEL Keelung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"基隆市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KEL = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KEL) == 0):\n",
    "            data_all_KEL.append(('0',))\n",
    "        \n",
    "        #新北市NTPC New_Taipei\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新北市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_NTPC = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_NTPC) == 0):\n",
    "            data_all_NTPC.append(('0',))\n",
    "        \n",
    "        #台北市TPE Taipei\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台北市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TPE = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TPE) == 0):\n",
    "            data_all_TPE.append(('0',))\n",
    "        \n",
    "        #桃園市TYN Taoyuan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"桃園市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TYN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TYN) == 0):\n",
    "            data_all_TYN.append(('0',))\n",
    "        \n",
    "        #新竹縣HSZ0 Hsinchu_County\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新竹縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HSZ0 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HSZ0) == 0):\n",
    "            data_all_HSZ0.append(('0',))\n",
    "        \n",
    "        #新竹市HSZ1 Hsinchu_City\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新竹市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HSZ1 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HSZ1) == 0):\n",
    "            data_all_HSZ1.append(('0',))\n",
    "        \n",
    "        #苗栗縣ZMI Miaoli\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"苗栗縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_ZMI = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_ZMI) == 0):\n",
    "            data_all_ZMI.append(('0',))\n",
    "        \n",
    "        #台中市TXG Taichung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台中市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TXG = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TXG) == 0):\n",
    "            data_all_TXG.append(('0',))\n",
    "        \n",
    "        #彰化縣CHW Changhua\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"彰化縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CHW = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CHW) == 0):\n",
    "            data_all_CHW.append(('0',))\n",
    "        \n",
    "        #南投縣NTC Nantou\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"南投縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_NTC = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_NTC) == 0):\n",
    "            data_all_NTC.append(('0',))\n",
    "        \n",
    "        #雲林縣YUN Yunlin\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"雲林縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_YUN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_YUN) == 0):\n",
    "            data_all_YUN.append(('0',))\n",
    "        \n",
    "        #嘉義縣CYI0 Chiayi_County\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"嘉義縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CYI0 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CYI0) == 0):\n",
    "            data_all_CYI0.append(('0',))\n",
    "        \n",
    "        #嘉義市CYI1 Chiayi_City\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"嘉義市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CYI1 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CYI1) == 0):\n",
    "            data_all_CYI1.append(('0',))\n",
    "        \n",
    "        #台南市TNN Tainan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台南市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TNN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TNN) == 0):\n",
    "            data_all_TNN.append(('0',))\n",
    "        \n",
    "        #高雄市KHH Kaohsiung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"高雄市\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KHH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KHH) == 0):\n",
    "            data_all_KHH.append(('0',))\n",
    "        \n",
    "        #屏東縣PIF Pingtung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"屏東縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_PIF = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_PIF) == 0):\n",
    "            data_all_PIF.append(('0',))\n",
    "        \n",
    "        #宜蘭縣ILA Yilan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"宜蘭縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_ILA = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_ILA) == 0):\n",
    "            data_all_ILA.append(('0',))\n",
    "        \n",
    "        #花蓮縣HUN Hualien\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"花蓮縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HUN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HUN) == 0):\n",
    "            data_all_HUN.append(('0',))\n",
    "        \n",
    "        #台東縣TTT Taitung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台東縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TTT = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TTT) == 0):\n",
    "            data_all_TTT.append(('0',))\n",
    "        \n",
    "        #澎湖縣PEH Penghu\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"澎湖縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_PEH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_PEH) == 0):\n",
    "            data_all_PEH.append(('0',))\n",
    "        \n",
    "        #金門縣KNH Kinmen\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"金門縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KNH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KNH) == 0):\n",
    "            data_all_KNH.append(('0',))\n",
    "        \n",
    "        #連江縣LNN Lienchiang\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"連江縣\" AND 個案研判日 = \"%s\" ;\"\"\" %(user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_LNN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_LNN) == 0):\n",
    "            data_all_LNN.append(('0',))\n",
    "\n",
    "    elif(user_input == '一周'):\n",
    "        user_date_ = (date + datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "        date_all = []\n",
    "        for i in range(7):\n",
    "            date_all += ((date + datetime.timedelta(days=i)).strftime(\"%Y-%m-%d\")).split()\n",
    "        print(date_all)\n",
    "        print(type(date_all))\n",
    "        patch_zero = (('0',),('0',),('0',),('0',),('0',),('0',),('0',))\n",
    "        \n",
    "        #基隆市KEL Keelung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"基隆市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KEL = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KEL) == 0):\n",
    "            data_all_KEL.extend(patch_zero)\n",
    "        \n",
    "        #新北市NTPC New_Taipei\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新北市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_NTPC = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_NTPC) == 0):\n",
    "            data_all_NTPC.extend(patch_zero)\n",
    "        \n",
    "        #台北市TPE Taipei\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台北市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TPE = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TPE) == 0):\n",
    "            data_all_TPE.extend(patch_zero)\n",
    "        \n",
    "        #桃園市TYN Taoyuan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"桃園市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TYN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TYN) == 0):\n",
    "            data_all_TYN.extend(patch_zero)\n",
    "        \n",
    "        #新竹縣HSZ0 Hsinchu_County\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新竹縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HSZ0 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HSZ0) == 0):\n",
    "            data_all_HSZ0.extend(patch_zero)\n",
    "        \n",
    "        #新竹市HSZ1 Hsinchu_City\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新竹市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HSZ1 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HSZ1) == 0):\n",
    "            data_all_HSZ1.extend(patch_zero)\n",
    "        \n",
    "        #苗栗縣ZMI Miaoli\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"苗栗縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_ZMI = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_ZMI) == 0):\n",
    "            data_all_ZMI.extend(patch_zero)\n",
    "        \n",
    "        #台中市TXG Taichung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台中市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TXG = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TXG) == 0):\n",
    "            data_all_TXG.extend(patch_zero)\n",
    "        \n",
    "        #彰化縣CHW Changhua\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"彰化縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CHW = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CHW) == 0):\n",
    "            data_all_CHW.extend(patch_zero)\n",
    "        \n",
    "        #南投縣NTC Nantou\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"南投縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_NTC = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_NTC) == 0):\n",
    "            data_all_NTC.extend(patch_zero)\n",
    "        \n",
    "        #雲林縣YUN Yunlin\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"雲林縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_YUN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_YUN) == 0):\n",
    "            data_all_YUN.extend(patch_zero)\n",
    "        \n",
    "        #嘉義縣CYI0 Chiayi_County\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"嘉義縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CYI0 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CYI0) == 0):\n",
    "            data_all_CYI0.extend(patch_zero)\n",
    "        \n",
    "        #嘉義市CYI1 Chiayi_City\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"嘉義市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CYI1 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CYI1) == 0):\n",
    "            data_all_CYI1.extend(patch_zero)\n",
    "        \n",
    "        #台南市TNN Tainan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台南市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TNN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TNN) == 0):\n",
    "            data_all_TNN.extend(patch_zero)\n",
    "        \n",
    "        #高雄市KHH Kaohsiung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"高雄市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KHH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KHH) == 0):\n",
    "            data_all_KHH.extend(patch_zero)\n",
    "        \n",
    "        #屏東縣PIF Pingtung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"屏東縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_PIF = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_PIF) == 0):\n",
    "            data_all_PIF.extend(patch_zero)\n",
    "        \n",
    "        #宜蘭縣ILA Yilan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"宜蘭縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_ILA = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_ILA) == 0):\n",
    "            data_all_ILA.extend(patch_zero)\n",
    "        \n",
    "        #花蓮縣HUN Hualien\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"花蓮縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HUN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HUN) == 0):\n",
    "            data_all_HUN.extend(patch_zero)\n",
    "        \n",
    "        #台東縣TTT Taitung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台東縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TTT = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TTT) == 0):\n",
    "            data_all_TTT.extend(patch_zero)\n",
    "        \n",
    "        #澎湖縣PEH Penghu\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"澎湖縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_PEH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_PEH) == 0):\n",
    "            data_all_PEH.extend(patch_zero)\n",
    "        \n",
    "        #金門縣KNH Kinmen\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"金門縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KNH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KNH) == 0):\n",
    "            data_all_KNH.extend(patch_zero)\n",
    "        \n",
    "        #連江縣LNN Lienchiang\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"連江縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_LNN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_LNN) == 0):\n",
    "            data_all_LNN.extend(patch_zero)\n",
    "            \n",
    "    elif(user_input == '一月'):\n",
    "        user_date_ = (date + relativedelta(months = +1)).strftime(\"%Y-%m-%d\")\n",
    "        d_start = datetime.datetime.strptime(user_date, \"%Y-%m-%d\")\n",
    "        d_end = datetime.datetime.strptime(user_date_, \"%Y-%m-%d\")\n",
    "        d_delta = d_end - d_start\n",
    "        date_all = []\n",
    "        patch_zero = []\n",
    "        for i in range(d_delta.days+1):\n",
    "            date_all += ((date + datetime.timedelta(days=i)).strftime(\"%Y-%m-%d\")).split()\n",
    "            patch_zero.append(('0',))\n",
    "        print(date_all)\n",
    "        print(type(date_all))\n",
    "        \n",
    "        #基隆市KEL Keelung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"基隆市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KEL = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KEL) == 0):\n",
    "            data_all_KEL.extend(patch_zero)\n",
    "        \n",
    "        #新北市NTPC New_Taipei\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新北市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_NTPC = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_NTPC) == 0):\n",
    "            data_all_NTPC.extend(patch_zero)\n",
    "        \n",
    "        #台北市TPE Taipei\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台北市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TPE = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TPE) == 0):\n",
    "            data_all_TPE.extend(patch_zero)\n",
    "        \n",
    "        #桃園市TYN Taoyuan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"桃園市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TYN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TYN) == 0):\n",
    "            data_all_TYN.extend(patch_zero)\n",
    "        \n",
    "        #新竹縣HSZ0 Hsinchu_County\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新竹縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HSZ0 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HSZ0) == 0):\n",
    "            data_all_HSZ0.extend(patch_zero)\n",
    "        \n",
    "        #新竹市HSZ1 Hsinchu_City\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"新竹市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HSZ1 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HSZ1) == 0):\n",
    "            data_all_HSZ1.extend(patch_zero)\n",
    "        \n",
    "        #苗栗縣ZMI Miaoli\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"苗栗縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_ZMI = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_ZMI) == 0):\n",
    "            data_all_ZMI.extend(patch_zero)\n",
    "        \n",
    "        #台中市TXG Taichung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台中市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TXG = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TXG) == 0):\n",
    "            data_all_TXG.extend(patch_zero)\n",
    "        \n",
    "        #彰化縣CHW Changhua\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"彰化縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CHW = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CHW) == 0):\n",
    "            data_all_CHW.extend(patch_zero)\n",
    "        \n",
    "        #南投縣NTC Nantou\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"南投縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_NTC = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_NTC) == 0):\n",
    "            data_all_NTC.extend(patch_zero)\n",
    "        \n",
    "        #雲林縣YUN Yunlin\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"雲林縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_YUN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_YUN) == 0):\n",
    "            data_all_YUN.extend(patch_zero)\n",
    "        \n",
    "        #嘉義縣CYI0 Chiayi_County\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"嘉義縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CYI0 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CYI0) == 0):\n",
    "            data_all_CYI0.extend(patch_zero)\n",
    "        \n",
    "        #嘉義市CYI1 Chiayi_City\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"嘉義市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_CYI1 = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_CYI1) == 0):\n",
    "            data_all_CYI1.extend(patch_zero)\n",
    "        \n",
    "        #台南市TNN Tainan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台南市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TNN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TNN) == 0):\n",
    "            data_all_TNN.extend(patch_zero)\n",
    "        \n",
    "        #高雄市KHH Kaohsiung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"高雄市\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KHH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KHH) == 0):\n",
    "            data_all_KHH.extend(patch_zero)\n",
    "        \n",
    "        #屏東縣PIF Pingtung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"屏東縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_PIF = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_PIF) == 0):\n",
    "            data_all_PIF.extend(patch_zero)\n",
    "        \n",
    "        #宜蘭縣ILA Yilan\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"宜蘭縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_ILA = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_ILA) == 0):\n",
    "            data_all_ILA.extend(patch_zero)\n",
    "        \n",
    "        #花蓮縣HUN Hualien\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"花蓮縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_HUN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_HUN) == 0):\n",
    "            data_all_HUN.extend(patch_zero)\n",
    "        \n",
    "        #台東縣TTT Taitung\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"台東縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_TTT = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_TTT) == 0):\n",
    "            data_all_TTT.extend(patch_zero)\n",
    "        \n",
    "        #澎湖縣PEH Penghu\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"澎湖縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_PEH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_PEH) == 0):\n",
    "            data_all_PEH.extend(patch_zero)\n",
    "        \n",
    "        #金門縣KNH Kinmen\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"金門縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_KNH = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_KNH) == 0):\n",
    "            data_all_KNH.extend(patch_zero)\n",
    "        \n",
    "        #連江縣LNN Lienchiang\n",
    "        sql = \"\"\" SELECT 確定病例數 from Taiwan where 縣市 = \"連江縣\" \n",
    "        AND 個案研判日 >= \"%s\" AND 個案研判日 <= \"%s\" ;\"\"\" %(user_date, user_date_)\n",
    "        db.engine.execute(sql) #執行 SQL 指令\n",
    "        data_all_LNN = db.engine.execute(sql).fetchall() #取出全部資料\n",
    "        if (len(data_all_LNN) == 0):\n",
    "            data_all_LNN.extend(patch_zero)\n",
    "        \n",
    "    \n",
    "    # list轉string後，取re數字(list)\n",
    "    data_re01 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_KEL))\n",
    "    data_re02 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_NTPC))\n",
    "    data_re03 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_TPE))\n",
    "    data_re04 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_TYN))\n",
    "    data_re05 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_HSZ0))\n",
    "    data_re06 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_HSZ1))\n",
    "    data_re07 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_ZMI))\n",
    "    data_re08 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_TXG))\n",
    "    data_re09 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_CHW))\n",
    "    data_re10 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_NTC))\n",
    "    data_re11 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_YUN))\n",
    "    data_re12 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_CYI0))\n",
    "    data_re13 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_CYI1))\n",
    "    data_re14 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_TNN))\n",
    "    data_re15 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_KHH))\n",
    "    data_re16 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_PIF))\n",
    "    data_re17 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_ILA))\n",
    "    data_re18 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_HUN))\n",
    "    data_re19 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_TTT))\n",
    "    data_re20 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_PEH))\n",
    "    data_re21 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_KNH))\n",
    "    data_re22 = re.findall(r\"\\d+\", \",\".join(\"%s\" %id for id in data_all_LNN))\n",
    "    \n",
    "    #用彰化data_re09來判斷list長度後，前面項目補0\n",
    "    for i in range(len(data_re09)-len(data_re01)):\n",
    "        data_re01.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re02)):\n",
    "        data_re02.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re03)):\n",
    "        data_re03.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re04)):\n",
    "        data_re04.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re05)):\n",
    "        data_re05.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re06)):\n",
    "        data_re06.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re07)):\n",
    "        data_re07.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re08)):\n",
    "        data_re08.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re10)):\n",
    "        data_re10.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re11)):\n",
    "        data_re11.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re12)):\n",
    "        data_re12.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re13)):\n",
    "        data_re13.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re14)):\n",
    "        data_re14.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re15)):\n",
    "        data_re15.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re16)):\n",
    "        data_re16.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re17)):\n",
    "        data_re17.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re18)):\n",
    "        data_re18.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re19)):\n",
    "        data_re19.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re20)):\n",
    "        data_re20.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re21)):\n",
    "        data_re21.insert(0, '0')\n",
    "    for i in range(len(data_re09)-len(data_re22)):\n",
    "        data_re22.insert(0, '0')\n",
    "    \n",
    "    # 全國人數加總list\n",
    "    data_all = []\n",
    "    data_allin = 0\n",
    "    for i in range(len(data_re09)): \n",
    "        total = (int(data_re01[i]) + int(data_re02[i]) + int(data_re03[i]) + int(data_re04[i]) + \n",
    "                 int(data_re05[i]) + int(data_re06[i]) + int(data_re07[i]) + int(data_re08[i]) + \n",
    "                 int(data_re09[i]) + int(data_re10[i]) + int(data_re11[i]) + int(data_re12[i]) + \n",
    "                 int(data_re13[i]) + int(data_re14[i]) + int(data_re15[i]) + int(data_re16[i]) + \n",
    "                 int(data_re17[i]) + int(data_re18[i]) + int(data_re19[i]) + int(data_re20[i]) + \n",
    "                 int(data_re21[i]) + int(data_re22[i]))\n",
    "        print(total)\n",
    "        data_all.append(total)\n",
    "        data_allin += total\n",
    "    print(data_all)\n",
    "    \n",
    "    # 日期最後一天的確診人數\n",
    "    today_data = data_all[-1]\n",
    "    data_KEL = data_re01[-1]\n",
    "    data_NTPC = data_re02[-1]\n",
    "    data_TPE = data_re03[-1]\n",
    "    data_TYN = data_re04[-1]\n",
    "    data_HSZ0 = data_re05[-1]\n",
    "    data_HSZ1 = data_re06[-1]\n",
    "    data_ZMI = data_re07[-1]\n",
    "    data_TXG = data_re08[-1]\n",
    "    data_CHW = data_re09[-1]\n",
    "    data_NTC = data_re10[-1]\n",
    "    data_YUN = data_re11[-1]\n",
    "    data_CYI0 = data_re12[-1]\n",
    "    data_CYI1 = data_re13[-1]\n",
    "    data_TNN = data_re14[-1]\n",
    "    data_KHH = data_re15[-1]\n",
    "    data_PIF = data_re16[-1]\n",
    "    data_ILA = data_re17[-1]\n",
    "    data_HUN = data_re18[-1]\n",
    "    data_TTT = data_re19[-1]\n",
    "    data_PEH = data_re20[-1]\n",
    "    data_KNH = data_re21[-1]\n",
    "    data_LNN = data_re22[-1]\n",
    "    \n",
    "    # 合併list，全部日期 + 全國確診人數\n",
    "    list_all = dict(zip(date_all, data_all))\n",
    "    \n",
    "    print(\"user_input：\", user_input, type(user_input)) #選擇幾天\n",
    "    print(\"user_date：\", user_date, type(user_date)) #選擇的日期\n",
    "    print(\"user_date_：\", user_date_, type(user_date_)) #相加後的日期\n",
    "    print(\"data_all_TPE：\", data_all_TPE, type(data_all_TPE)) #執行sql指令後的data\n",
    "    print(\"data_re03：\", data_re03, type(data_re03)) #list轉string後，取re數字(list)\n",
    "    print(\"data_all：\", data_all, type(data_all)) #全國人數加總list\n",
    "    print(\"today_data：\", today_data, type(today_data)) #日期最後一天的全國確診人數\n",
    "    print(\"data_TPE：\", data_TPE, type(data_TPE)) #日期最後一天的TPE確診人數\n",
    "    print(\"list_all：\", list_all, type(list_all)) #合併list\n",
    "    \n",
    "    #with urllib.request.urlopen(second_url) as response:\n",
    "        #second = response.read()\n",
    "    #return second\n",
    "    return render_template(\"second_web.html\", **locals())\n",
    "\n",
    "@app.route('/predict',methods=[\"POST\"])\n",
    "def predict():\n",
    "    if request.method == \"POST\":\n",
    "        user_input = request.values['user_input']\n",
    "    if(user_input == '一月'):\n",
    "        predict_days=30\n",
    "        #print(date_all)\n",
    "        #print(type(date_all))\n",
    "        #Load the trained model. (Pickle file)\n",
    "        model = load_model('models/taichung_rnn+lstm_1000_1.h5')\n",
    "        ######################################台北市######################################\n",
    "\t    # 載入訓練資料\n",
    "        model_TPE = load_model('models/taipei_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TPE = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台北市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TPE=dataframe_TPE.drop(dataframe_TPE[dataframe_TPE['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TPE.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TPE_Predict = model_TPE.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TPE_Predict = scaler.inverse_transform(TPE_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TPE_PredictPlot = numpy.empty_like(dataset)\n",
    "        TPE_PredictPlot[:, :] = numpy.nan\n",
    "        TPE_PredictPlot[look_back:len(TPE_Predict)+look_back, :] = TPE_Predict\n",
    "        plt.plot(TPE_PredictPlot)\n",
    "        plt.savefig('./static/TPE_plot.png') \n",
    "        plt.clf()\n",
    "        #################################################################################\n",
    "        ######################################基隆市######################################\n",
    "        model_KEL = load_model('models/keelung_rnn+lstm_1000_2.h5')\n",
    "        dataframe_KEL = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\基隆市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_KEL=dataframe_KEL.drop(dataframe_KEL[dataframe_KEL['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_KEL.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        KEL_Predict = model_KEL.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        KEL_Predict = scaler.inverse_transform(KEL_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    #shift train predictions for plotting\n",
    "        KEL_PredictPlot = numpy.empty_like(dataset)\n",
    "        KEL_PredictPlot[:, :] = numpy.nan\n",
    "        KEL_PredictPlot[look_back:len(KEL_Predict)+look_back, :] = KEL_Predict\n",
    "        plt.plot(KEL_PredictPlot)\n",
    "        plt.savefig('KEL_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################新北市######################################\n",
    "        dataframe_NTPC = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\新北市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_NTPC=dataframe_NTPC.drop(dataframe_NTPC[dataframe_NTPC['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_NTPC.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        NTPC_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        NTPC_Predict = scaler.inverse_transform(NTPC_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        NTPC_PredictPlot = numpy.empty_like(dataset)\n",
    "        NTPC_PredictPlot[:, :] = numpy.nan\n",
    "        NTPC_PredictPlot[look_back:len(NTPC_Predict)+look_back, :] = NTPC_Predict\n",
    "        plt.plot(NTPC_PredictPlot)\n",
    "        plt.savefig('./static/NTPC_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################新竹市######################################\n",
    "        dataframe_HSZ1 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\新竹市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_HSZ1=dataframe_HSZ1.drop(dataframe_HSZ1[dataframe_HSZ1['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_HSZ1.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        HSZ1_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        HSZ1_Predict = scaler.inverse_transform(HSZ1_Predict)\n",
    "        testY = scaler.inverse_transform([testY])\n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        HSZ1_PredictPlot = numpy.empty_like(dataset)\n",
    "        HSZ1_PredictPlot[:, :] = numpy.nan\n",
    "        HSZ1_PredictPlot[look_back:len(HSZ1_Predict)+look_back, :] = HSZ1_Predict\n",
    "        plt.plot(HSZ1_PredictPlot)\n",
    "        plt.savefig('./static/HSZ1_plot.png')\n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################新竹縣######################################\n",
    "        dataframe_HSZ0 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\新竹縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_HSZ0=dataframe_HSZ0.drop(dataframe_HSZ0[dataframe_HSZ0['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_HSZ0.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        HSZ0_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        HSZ0_Predict = scaler.inverse_transform(HSZ0_Predict)\n",
    "        testY = scaler.inverse_transform([testY])\n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        HSZ0_PredictPlot = numpy.empty_like(dataset)\n",
    "        HSZ0_PredictPlot[:, :] = numpy.nan\n",
    "        HSZ0_PredictPlot[look_back:len(HSZ0_Predict)+look_back, :] = HSZ0_Predict\n",
    "        plt.plot(HSZ0_PredictPlot)\n",
    "        plt.savefig('./static/HSZ0_plot.png')\n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################苗栗縣######################################\n",
    "        dataframe_ZMI = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\苗栗縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_ZMI=dataframe_ZMI.drop(dataframe_ZMI[dataframe_ZMI['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_ZMI.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        ZMI_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        ZMI_Predict = scaler.inverse_transform(ZMI_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        ZMI_PredictPlot = numpy.empty_like(dataset)\n",
    "        ZMI_PredictPlot[:, :] = numpy.nan\n",
    "        ZMI_PredictPlot[look_back:len(ZMI_Predict)+look_back, :] = ZMI_Predict\n",
    "        plt.plot(ZMI_PredictPlot)\n",
    "        plt.savefig('./static/ZMI_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################桃園市######################################\n",
    "        dataframe_TYN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\桃園市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TYN=dataframe_TYN.drop(dataframe_TYN[dataframe_TYN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TYN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TYN_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TYN_Predict = scaler.inverse_transform(TYN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TYN_PredictPlot = numpy.empty_like(dataset)\n",
    "        TYN_PredictPlot[:, :] = numpy.nan\n",
    "        TYN_PredictPlot[look_back:len(TYN_Predict)+look_back, :] = TYN_Predict\n",
    "        plt.plot(TYN_PredictPlot)\n",
    "        plt.savefig('./static/TYN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################台中市######################################\n",
    "        model_TXG = load_model('models/taichung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TXG = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台中市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TXG=dataframe_TXG.drop(dataframe_TXG[dataframe_TXG['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TXG.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TXG_Predict = model_TXG.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TXG_Predict = scaler.inverse_transform(TXG_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TXG_PredictPlot = numpy.empty_like(dataset)\n",
    "        TXG_PredictPlot[:, :] = numpy.nan\n",
    "        TXG_PredictPlot[look_back:len(TXG_Predict)+look_back, :] = TXG_Predict\n",
    "        plt.plot(TXG_PredictPlot)\n",
    "        plt.savefig('./static/TXG_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################彰化縣######################################\n",
    "        #model_CHW = load_model('models/taichung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_CHW = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\彰化縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_CHW=dataframe_CHW.drop(dataframe_CHW[dataframe_CHW['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_CHW.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        CHW_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        CHW_Predict = scaler.inverse_transform(CHW_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        CHW_PredictPlot = numpy.empty_like(dataset)\n",
    "        CHW_PredictPlot[:, :] = numpy.nan\n",
    "        CHW_PredictPlot[look_back:len(CHW_Predict)+look_back, :] = CHW_Predict\n",
    "        plt.plot(CHW_PredictPlot)\n",
    "        plt.savefig('./static/CHW_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################南投縣######################################\n",
    "        model_NTC = load_model('models/nantou_rnn+lstm_1000_1.h5')\n",
    "        dataframe_NTC = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\彰化縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_NTC=dataframe_NTC.drop(dataframe_NTC[dataframe_NTC['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_NTC.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        NTC_Predict = model_NTC.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        NTC_Predict = scaler.inverse_transform(NTC_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        NTC_PredictPlot = numpy.empty_like(dataset)\n",
    "        NTC_PredictPlot[:, :] = numpy.nan\n",
    "        NTC_PredictPlot[look_back:len(NTC_Predict)+look_back, :] = NTC_Predict\n",
    "        plt.plot(NTC_PredictPlot)\n",
    "        plt.savefig('./static/NTC_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################雲林縣######################################\n",
    "        dataframe_YUN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\雲林縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_YUN=dataframe_YUN.drop(dataframe_YUN[dataframe_YUN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_YUN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        YUN_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        YUN_Predict = scaler.inverse_transform(YUN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        YUN_PredictPlot = numpy.empty_like(dataset)\n",
    "        YUN_PredictPlot[:, :] = numpy.nan\n",
    "        YUN_PredictPlot[look_back:len(YUN_Predict)+look_back, :] = YUN_Predict\n",
    "        plt.plot(YUN_PredictPlot)\n",
    "        plt.savefig('./static/YUN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################嘉義縣######################################\n",
    "        dataframe_CYI0 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\嘉義縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_CYI0=dataframe_CYI0.drop(dataframe_CYI0[dataframe_CYI0['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_CYI0.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        CYI0_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        CYI0_Predict = scaler.inverse_transform(CYI0_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        CYI0_PredictPlot = numpy.empty_like(dataset)\n",
    "        CYI0_PredictPlot[:, :] = numpy.nan\n",
    "        CYI0_PredictPlot[look_back:len(CYI0_Predict)+look_back, :] = CYI0_Predict\n",
    "        plt.plot(CYI0_PredictPlot)\n",
    "        plt.savefig('./static/CYI0_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################嘉義市######################################\n",
    "        dataframe_CYI1 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\嘉義市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_CYI1=dataframe_CYI1.drop(dataframe_CYI1[dataframe_CYI1['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_CYI1.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        CYI1_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        CYI1_Predict = scaler.inverse_transform(CYI1_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        CYI1_PredictPlot = numpy.empty_like(dataset)\n",
    "        CYI1_PredictPlot[:, :] = numpy.nan\n",
    "        CYI1_PredictPlot[look_back:len(CYI1_Predict)+look_back, :] = CYI1_Predict\n",
    "        plt.plot(CYI1_PredictPlot)\n",
    "        plt.savefig('./static/CYI1_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################台南市######################################\n",
    "        model_TNN = load_model('models/tainan_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TNN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台南市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TNN=dataframe_TNN.drop(dataframe_TNN[dataframe_TNN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TNN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TNN_Predict = model_TNN.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TNN_Predict = scaler.inverse_transform(TNN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TNN_PredictPlot = numpy.empty_like(dataset)\n",
    "        TNN_PredictPlot[:, :] = numpy.nan\n",
    "        TNN_PredictPlot[look_back:len(TNN_Predict)+look_back, :] = TNN_Predict\n",
    "        plt.plot(TNN_PredictPlot)\n",
    "        plt.savefig('./static/TNN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################高雄市######################################\n",
    "        dataframe_KHH = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\高雄市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_KHH=dataframe_KHH.drop(dataframe_KHH[dataframe_KHH['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_KHH.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        KHH_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        KHH_Predict = scaler.inverse_transform(KHH_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        KHH_PredictPlot = numpy.empty_like(dataset)\n",
    "        KHH_PredictPlot[:, :] = numpy.nan\n",
    "        KHH_PredictPlot[look_back:len(KHH_Predict)+look_back, :] = KHH_Predict\n",
    "        plt.plot(KHH_PredictPlot)\n",
    "        plt.savefig('./static/KHH_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################屏東縣######################################\n",
    "        model_PIF = load_model('models/pingtung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_PIF = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\屏東縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_PIF=dataframe_PIF.drop(dataframe_PIF[dataframe_PIF['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_PIF.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        PIF_Predict = model_PIF.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        PIF_Predict = scaler.inverse_transform(PIF_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        PIF_PredictPlot = numpy.empty_like(dataset)\n",
    "        PIF_PredictPlot[:, :] = numpy.nan\n",
    "        PIF_PredictPlot[look_back:len(PIF_Predict)+look_back, :] = PIF_Predict\n",
    "        plt.plot(PIF_PredictPlot)\n",
    "        plt.savefig('./static/PIF_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################宜蘭縣######################################\n",
    "        model_ILA = load_model('models/yilan_rnn+lstm_1000_1.h5')\n",
    "        dataframe_ILA = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\宜蘭縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_ILA=dataframe_ILA.drop(dataframe_ILA[dataframe_ILA['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_ILA.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        ILA_Predict = model_ILA.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        ILA_Predict = scaler.inverse_transform(ILA_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        ILA_PredictPlot = numpy.empty_like(dataset)\n",
    "        ILA_PredictPlot[:, :] = numpy.nan\n",
    "        ILA_PredictPlot[look_back:len(ILA_Predict)+look_back, :] = ILA_Predict\n",
    "        plt.plot(ILA_PredictPlot)\n",
    "        plt.savefig('./static/ILA_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################花蓮縣######################################\n",
    "        model_HUN = load_model('models/hualien_rnn+lstm_1000_1.h5')\n",
    "        dataframe_HUN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\花蓮縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_HUN=dataframe_HUN.drop(dataframe_HUN[dataframe_HUN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_HUN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        HUN_Predict = model_HUN.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        HUN_Predict = scaler.inverse_transform(HUN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        HUN_PredictPlot = numpy.empty_like(dataset)\n",
    "        HUN_PredictPlot[:, :] = numpy.nan\n",
    "        HUN_PredictPlot[look_back:len(HUN_Predict)+look_back, :] = HUN_Predict\n",
    "        plt.plot(HUN_PredictPlot)\n",
    "        plt.savefig('./static/HUN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################台東縣######################################\n",
    "        model_TTT = load_model('models/taitung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TTT = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台東縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TTT=dataframe_TTT.drop(dataframe_TTT[dataframe_TTT['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TTT.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TTT_Predict = model_TTT.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TTT_Predict = scaler.inverse_transform(TTT_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TTT_PredictPlot = numpy.empty_like(dataset)\n",
    "        TTT_PredictPlot[:, :] = numpy.nan\n",
    "        TTT_PredictPlot[look_back:len(TTT_Predict)+look_back, :] = TTT_Predict\n",
    "        plt.plot(TTT_PredictPlot)\n",
    "        plt.savefig('./static/TTT_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################澎湖縣######################################\n",
    "        model_PEH = load_model('models/penghu_rnn+lstm_5000_2.h5')\n",
    "        dataframe_PEH = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\澎湖縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_PEH=dataframe_PEH.drop(dataframe_PEH[dataframe_PEH['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_PEH.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        PEH_Predict = model_PEH.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        PEH_Predict = scaler.inverse_transform(PEH_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        PEH_PredictPlot = numpy.empty_like(dataset)\n",
    "        PEH_PredictPlot[:, :] = numpy.nan\n",
    "        PEH_PredictPlot[look_back:len(PEH_Predict)+look_back, :] = PEH_Predict\n",
    "        plt.plot(PEH_PredictPlot)\n",
    "        plt.savefig('./static/PEH_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################金門縣######################################\n",
    "        model_KNH = load_model('models/kinmen_rnn+lstm_1000_1.h5')\n",
    "        dataframe_KNH = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\金門縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_KNH=dataframe_KNH.drop(dataframe_KNH[dataframe_KNH['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_KNH.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        KNH_Predict = model_KNH.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        KNH_Predict = scaler.inverse_transform(KNH_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        KNH_PredictPlot = numpy.empty_like(dataset)\n",
    "        KNH_PredictPlot[:, :] = numpy.nan\n",
    "        KNH_PredictPlot[look_back:len(KNH_Predict)+look_back, :] = KNH_Predict\n",
    "        plt.plot(KNH_PredictPlot)\n",
    "        plt.savefig('./static/KNH_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################連江縣######################################\n",
    "        model_LNN = load_model('models/lienchiang_rnn+lstm_1000_2.h5')\n",
    "        dataframe_LNN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\連江縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_LNN=dataframe_LNN.drop(dataframe_LNN[dataframe_LNN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_LNN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 30\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        LNN_Predict = model_LNN.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        LNN_Predict = scaler.inverse_transform(LNN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        LNN_PredictPlot = numpy.empty_like(dataset)\n",
    "        LNN_PredictPlot[:, :] = numpy.nan\n",
    "        LNN_PredictPlot[look_back:len(LNN_Predict)+look_back, :] = LNN_Predict\n",
    "        plt.plot(LNN_PredictPlot)\n",
    "        plt.savefig('./static/LNN_plot.png') \n",
    "        plt.clf()\n",
    "    if(user_input == '一周'):\n",
    "        predict_days=7\n",
    "        #print(date_all)\n",
    "        #print(type(date_all))\n",
    "        #Load the trained model. (Pickle file)\n",
    "        model = load_model('models/taichung_rnn+lstm_1000_1.h5')\n",
    "        ######################################台北市######################################\n",
    "\t    # 載入訓練資料\n",
    "        model_TPE = load_model('models/taipei_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TPE = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台北市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TPE=dataframe_TPE.drop(dataframe_TPE[dataframe_TPE['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TPE.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TPE_Predict = model_TPE.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TPE_Predict = scaler.inverse_transform(TPE_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TPE_PredictPlot = numpy.empty_like(dataset)\n",
    "        TPE_PredictPlot[:, :] = numpy.nan\n",
    "        TPE_PredictPlot[look_back:len(TPE_Predict)+look_back, :] = TPE_Predict\n",
    "        plt.plot(TPE_PredictPlot)\n",
    "        plt.savefig('./static/TPE_plot.png') \n",
    "        plt.clf()\n",
    "        #################################################################################\n",
    "        ######################################基隆市######################################\n",
    "        model_KEL = load_model('models/keelung_rnn+lstm_1000_2.h5')\n",
    "        dataframe_KEL = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\基隆市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_KEL=dataframe_KEL.drop(dataframe_KEL[dataframe_KEL['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_KEL.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        KEL_Predict = model_KEL.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        KEL_Predict = scaler.inverse_transform(KEL_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    #shift train predictions for plotting\n",
    "        KEL_PredictPlot = numpy.empty_like(dataset)\n",
    "        KEL_PredictPlot[:, :] = numpy.nan\n",
    "        KEL_PredictPlot[look_back:len(KEL_Predict)+look_back, :] = KEL_Predict\n",
    "        plt.plot(KEL_PredictPlot)\n",
    "        plt.savefig('./static/KEL_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################新北市######################################\n",
    "        dataframe_NTPC = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\新北市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_NTPC=dataframe_NTPC.drop(dataframe_NTPC[dataframe_NTPC['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_NTPC.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        NTPC_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        NTPC_Predict = scaler.inverse_transform(NTPC_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        NTPC_PredictPlot = numpy.empty_like(dataset)\n",
    "        NTPC_PredictPlot[:, :] = numpy.nan\n",
    "        NTPC_PredictPlot[look_back:len(NTPC_Predict)+look_back, :] = NTPC_Predict\n",
    "        plt.plot(NTPC_PredictPlot)\n",
    "        plt.savefig('./static/NTPC_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################新竹市######################################\n",
    "        dataframe_HSZ1 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\新竹市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_HSZ1=dataframe_HSZ1.drop(dataframe_HSZ1[dataframe_HSZ1['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_HSZ1.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        HSZ1_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        HSZ1_Predict = scaler.inverse_transform(HSZ1_Predict)\n",
    "        testY = scaler.inverse_transform([testY])\n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        HSZ1_PredictPlot = numpy.empty_like(dataset)\n",
    "        HSZ1_PredictPlot[:, :] = numpy.nan\n",
    "        HSZ1_PredictPlot[look_back:len(HSZ1_Predict)+look_back, :] = HSZ1_Predict\n",
    "        plt.plot(HSZ1_PredictPlot)\n",
    "        plt.savefig('./static/HSZ1_plot.png')\n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################新竹縣######################################\n",
    "        dataframe_HSZ0 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\新竹縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_HSZ0=dataframe_HSZ0.drop(dataframe_HSZ0[dataframe_HSZ0['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_HSZ0.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        HSZ0_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        HSZ0_Predict = scaler.inverse_transform(HSZ0_Predict)\n",
    "        testY = scaler.inverse_transform([testY])\n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        HSZ0_PredictPlot = numpy.empty_like(dataset)\n",
    "        HSZ0_PredictPlot[:, :] = numpy.nan\n",
    "        HSZ0_PredictPlot[look_back:len(HSZ0_Predict)+look_back, :] = HSZ0_Predict\n",
    "        plt.plot(HSZ0_PredictPlot)\n",
    "        plt.savefig('./static/HSZ0_plot.png')\n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################苗栗縣######################################\n",
    "        dataframe_ZMI = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\苗栗縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_ZMI=dataframe_ZMI.drop(dataframe_ZMI[dataframe_ZMI['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_ZMI.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        ZMI_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        ZMI_Predict = scaler.inverse_transform(ZMI_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        ZMI_PredictPlot = numpy.empty_like(dataset)\n",
    "        ZMI_PredictPlot[:, :] = numpy.nan\n",
    "        ZMI_PredictPlot[look_back:len(ZMI_Predict)+look_back, :] = ZMI_Predict\n",
    "        plt.plot(ZMI_PredictPlot)\n",
    "        plt.savefig('./static/ZMI_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################桃園市######################################\n",
    "        dataframe_TYN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\桃園市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TYN=dataframe_TYN.drop(dataframe_TYN[dataframe_TYN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TYN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TYN_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TYN_Predict = scaler.inverse_transform(TYN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TYN_PredictPlot = numpy.empty_like(dataset)\n",
    "        TYN_PredictPlot[:, :] = numpy.nan\n",
    "        TYN_PredictPlot[look_back:len(TYN_Predict)+look_back, :] = TYN_Predict\n",
    "        plt.plot(TYN_PredictPlot)\n",
    "        plt.savefig('./static/TYN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################台中市######################################\n",
    "        model_TXG = load_model('models/taichung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TXG = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台中市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TXG=dataframe_TXG.drop(dataframe_TXG[dataframe_TXG['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TXG.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TXG_Predict = model_TXG.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TXG_Predict = scaler.inverse_transform(TXG_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TXG_PredictPlot = numpy.empty_like(dataset)\n",
    "        TXG_PredictPlot[:, :] = numpy.nan\n",
    "        TXG_PredictPlot[look_back:len(TXG_Predict)+look_back, :] = TXG_Predict\n",
    "        plt.plot(TXG_PredictPlot)\n",
    "        plt.savefig('./static/TXG_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################彰化縣######################################\n",
    "        dataframe_CHW = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\彰化縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_CHW=dataframe_CHW.drop(dataframe_CHW[dataframe_CHW['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_CHW.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        CHW_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        CHW_Predict = scaler.inverse_transform(CHW_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        CHW_PredictPlot = numpy.empty_like(dataset)\n",
    "        CHW_PredictPlot[:, :] = numpy.nan\n",
    "        CHW_PredictPlot[look_back:len(CHW_Predict)+look_back, :] = CHW_Predict\n",
    "        plt.plot(CHW_PredictPlot)\n",
    "        plt.savefig('./static/CHW_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################南投縣######################################\n",
    "        model_NTC = load_model('models/nantou_rnn+lstm_1000_1.h5')\n",
    "        dataframe_NTC = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\彰化縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_NTC=dataframe_NTC.drop(dataframe_NTC[dataframe_NTC['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_NTC.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        NTC_Predict = model_NTC.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        NTC_Predict = scaler.inverse_transform(NTC_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        NTC_PredictPlot = numpy.empty_like(dataset)\n",
    "        NTC_PredictPlot[:, :] = numpy.nan\n",
    "        NTC_PredictPlot[look_back:len(NTC_Predict)+look_back, :] = NTC_Predict\n",
    "        plt.plot(NTC_PredictPlot)\n",
    "        plt.savefig('./static/NTC_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################雲林縣######################################\n",
    "        dataframe_YUN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\雲林縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_YUN=dataframe_YUN.drop(dataframe_YUN[dataframe_YUN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_YUN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        YUN_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        YUN_Predict = scaler.inverse_transform(YUN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        YUN_PredictPlot = numpy.empty_like(dataset)\n",
    "        YUN_PredictPlot[:, :] = numpy.nan\n",
    "        YUN_PredictPlot[look_back:len(YUN_Predict)+look_back, :] = YUN_Predict\n",
    "        plt.plot(YUN_PredictPlot)\n",
    "        plt.savefig('./static/YUN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################嘉義縣######################################\n",
    "        dataframe_CYI0 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\嘉義縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_CYI0=dataframe_CYI0.drop(dataframe_CYI0[dataframe_CYI0['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_CYI0.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        CYI0_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        CYI0_Predict = scaler.inverse_transform(CYI0_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        CYI0_PredictPlot = numpy.empty_like(dataset)\n",
    "        CYI0_PredictPlot[:, :] = numpy.nan\n",
    "        CYI0_PredictPlot[look_back:len(CYI0_Predict)+look_back, :] = CYI0_Predict\n",
    "        plt.plot(CYI0_PredictPlot)\n",
    "        plt.savefig('./static/CYI0_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################嘉義市######################################\n",
    "        dataframe_CYI1 = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\嘉義市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_CYI1=dataframe_CYI1.drop(dataframe_CYI1[dataframe_CYI1['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_CYI1.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        CYI1_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        CYI1_Predict = scaler.inverse_transform(CYI1_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        CYI1_PredictPlot = numpy.empty_like(dataset)\n",
    "        CYI1_PredictPlot[:, :] = numpy.nan\n",
    "        CYI1_PredictPlot[look_back:len(CYI1_Predict)+look_back, :] = CYI1_Predict\n",
    "        plt.plot(CYI1_PredictPlot)\n",
    "        plt.savefig('./static/CYI1_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################台南市######################################\n",
    "        model_TNN = load_model('models/tainan_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TNN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台南市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TNN=dataframe_TNN.drop(dataframe_TNN[dataframe_TNN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TNN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TNN_Predict = model_TNN.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TNN_Predict = scaler.inverse_transform(TNN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TNN_PredictPlot = numpy.empty_like(dataset)\n",
    "        TNN_PredictPlot[:, :] = numpy.nan\n",
    "        TNN_PredictPlot[look_back:len(TNN_Predict)+look_back, :] = TNN_Predict\n",
    "        plt.plot(TNN_PredictPlot)\n",
    "        plt.savefig('./static/TNN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################高雄市######################################\n",
    "        dataframe_KHH = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\高雄市每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_KHH=dataframe_KHH.drop(dataframe_KHH[dataframe_KHH['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_KHH.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        KHH_Predict = model.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        KHH_Predict = scaler.inverse_transform(KHH_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        KHH_PredictPlot = numpy.empty_like(dataset)\n",
    "        KHH_PredictPlot[:, :] = numpy.nan\n",
    "        KHH_PredictPlot[look_back:len(KHH_Predict)+look_back, :] = KHH_Predict\n",
    "        plt.plot(KHH_PredictPlot)\n",
    "        plt.savefig('./static/KHH_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################屏東縣######################################\n",
    "        model_PIF = load_model('models/pingtung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_PIF = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\屏東縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_PIF=dataframe_PIF.drop(dataframe_PIF[dataframe_PIF['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_PIF.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        PIF_Predict = model_PIF.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        PIF_Predict = scaler.inverse_transform(PIF_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        PIF_PredictPlot = numpy.empty_like(dataset)\n",
    "        PIF_PredictPlot[:, :] = numpy.nan\n",
    "        PIF_PredictPlot[look_back:len(PIF_Predict)+look_back, :] = PIF_Predict\n",
    "        plt.plot(PIF_PredictPlot)\n",
    "        plt.savefig('./static/PIF_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################宜蘭縣######################################\n",
    "        model_ILA = load_model('models/yilan_rnn+lstm_1000_1.h5')\n",
    "        dataframe_ILA = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\宜蘭縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_ILA=dataframe_ILA.drop(dataframe_ILA[dataframe_ILA['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_ILA.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        ILA_Predict = model_ILA.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        ILA_Predict = scaler.inverse_transform(ILA_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        ILA_PredictPlot = numpy.empty_like(dataset)\n",
    "        ILA_PredictPlot[:, :] = numpy.nan\n",
    "        ILA_PredictPlot[look_back:len(ILA_Predict)+look_back, :] = ILA_Predict\n",
    "        plt.plot(ILA_PredictPlot)\n",
    "        plt.savefig('./static/ILA_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################花蓮縣######################################\n",
    "        model_HUN = load_model('models/hualien_rnn+lstm_1000_1.h5')\n",
    "        dataframe_HUN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\花蓮縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_HUN=dataframe_HUN.drop(dataframe_HUN[dataframe_HUN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_HUN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        HUN_Predict = model_HUN.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        HUN_Predict = scaler.inverse_transform(HUN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        HUN_PredictPlot = numpy.empty_like(dataset)\n",
    "        HUN_PredictPlot[:, :] = numpy.nan\n",
    "        HUN_PredictPlot[look_back:len(HUN_Predict)+look_back, :] = HUN_Predict\n",
    "        plt.plot(HUN_PredictPlot)\n",
    "        plt.savefig('./static/HUN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################台東縣######################################\n",
    "        model_TTT = load_model('models/taitung_rnn+lstm_1000_1.h5')\n",
    "        dataframe_TTT = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\台東縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_TTT=dataframe_TTT.drop(dataframe_TTT[dataframe_TTT['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_TTT.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        TTT_Predict = model_TTT.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        TTT_Predict = scaler.inverse_transform(TTT_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        TTT_PredictPlot = numpy.empty_like(dataset)\n",
    "        TTT_PredictPlot[:, :] = numpy.nan\n",
    "        TTT_PredictPlot[look_back:len(TTT_Predict)+look_back, :] = TTT_Predict\n",
    "        plt.plot(TTT_PredictPlot)\n",
    "        plt.savefig('./static/TTT_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################澎湖縣######################################\n",
    "        model_PEH = load_model('models/penghu_rnn+lstm_5000_2.h5')\n",
    "        dataframe_PEH = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\澎湖縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_PEH=dataframe_PEH.drop(dataframe_PEH[dataframe_PEH['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_PEH.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        PEH_Predict = model_PEH.predict(testX)\n",
    "\n",
    "        PEH_Predict=PEH_Predict.reshape(-1, 1)\n",
    "\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        PEH_Predict = scaler.inverse_transform(PEH_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        PEH_PredictPlot = numpy.empty_like(dataset)\n",
    "        PEH_PredictPlot[:, :] = numpy.nan\n",
    "        PEH_PredictPlot[look_back:len(PEH_Predict)+look_back, :] = PEH_Predict\n",
    "        plt.plot(PEH_PredictPlot)\n",
    "        plt.savefig('./static/PEH_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################金門縣######################################\n",
    "        model_KNH = load_model('models/kinmen_rnn+lstm_1000_1.h5')\n",
    "        dataframe_KNH = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\金門縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_KNH=dataframe_KNH.drop(dataframe_KNH[dataframe_KNH['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_KNH.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        KNH_Predict = model_KNH.predict(testX)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        KNH_Predict = scaler.inverse_transform(KNH_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        KNH_PredictPlot = numpy.empty_like(dataset)\n",
    "        KNH_PredictPlot[:, :] = numpy.nan\n",
    "        KNH_PredictPlot[look_back:len(KNH_Predict)+look_back, :] = KNH_Predict\n",
    "        plt.plot(KNH_PredictPlot)\n",
    "        plt.savefig('./static/KNH_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "        ######################################連江縣######################################\n",
    "        model_LNN = load_model('models/lienchiang_rnn+lstm_1000_2.h5')\n",
    "        dataframe_LNN = pandas.read_csv('files_for_training_model\\各縣市每日確診資料\\連江縣每日確診數.csv', usecols=[2], engine='python', skipfooter=0,encoding='utf-8')\n",
    "        dataframe_LNN=dataframe_LNN.drop(dataframe_LNN[dataframe_LNN['確定病例數']==0].index,axis=0)\n",
    "        dataset = dataframe_LNN.values\n",
    "\t    # 正規化(normalize) 資料，使資料值介於[0, 1]\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        tf.random.set_seed(7)\n",
    "        test_size = 9\n",
    "        test = dataset[len(dataset)-test_size:,:]\n",
    "\t    # 產生 (X, Y) 資料集, Y 是下一期的確診數(reshape into X=t and Y=t+1)\n",
    "        look_back = 1\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "\t    # reshape input to be [samples, time steps, features]\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        LNN_Predict = model_LNN.predict(testX)\n",
    "\n",
    "        LNN_Predict=LNN_Predict.reshape(-1, 1)\n",
    "\t    # 回復預測資料值為原始數據的規模\n",
    "        LNN_Predict = scaler.inverse_transform(LNN_Predict)\n",
    "        testY = scaler.inverse_transform([testY]) \n",
    "\t    # 畫訓練資料趨勢圖\n",
    "\t    # shift train predictions for plotting\n",
    "        LNN_PredictPlot = numpy.empty_like(dataset)\n",
    "        LNN_PredictPlot[:, :] = numpy.nan\n",
    "        LNN_PredictPlot[look_back:len(LNN_Predict)+look_back, :] = LNN_Predict\n",
    "        plt.plot(LNN_PredictPlot)\n",
    "        plt.savefig('./static/LNN_plot.png') \n",
    "        plt.clf()\n",
    "\t    #################################################################################\n",
    "\n",
    "\n",
    "    KEL_Predict[KEL_Predict < 0] = 0\n",
    "    NTPC_Predict[NTPC_Predict < 0] = 0\n",
    "    TPE_Predict[TPE_Predict < 0] = 0\n",
    "    TYN_Predict[TYN_Predict < 0] = 0\n",
    "    HSZ0_Predict[HSZ0_Predict < 0] = 0\n",
    "    HSZ1_Predict[HSZ1_Predict < 0] = 0\n",
    "    ZMI_Predict[ZMI_Predict < 0] = 0\n",
    "    TXG_Predict[TXG_Predict < 0] = 0\n",
    "    CHW_Predict[CHW_Predict < 0] = 0\n",
    "    NTC_Predict[NTC_Predict < 0] = 0\n",
    "    YUN_Predict[YUN_Predict < 0] = 0\n",
    "    CYI0_Predict[CYI0_Predict < 0] = 0\n",
    "    CYI1_Predict[CYI1_Predict < 0] = 0\n",
    "    TNN_Predict[TNN_Predict < 0] = 0\n",
    "    KHH_Predict[KHH_Predict < 0] = 0\n",
    "    PIF_Predict[PIF_Predict < 0] = 0\n",
    "    ILA_Predict[ILA_Predict < 0] = 0\n",
    "    HUN_Predict[HUN_Predict < 0] = 0\n",
    "    TTT_Predict[TTT_Predict < 0] = 0\n",
    "    PEH_Predict[PEH_Predict < 0] = 0\n",
    "    KNH_Predict[KNH_Predict < 0] = 0\n",
    "    LNN_Predict[LNN_Predict < 0] = 0\n",
    "    data_re01 = [int(x) for x in KEL_Predict]\n",
    "    data_re02 = [int(x) for x in NTPC_Predict]\n",
    "    data_re03 = [int(x) for x in TPE_Predict]\n",
    "    data_re04 = [int(x) for x in TYN_Predict]\n",
    "    data_re05 = [int(x) for x in HSZ0_Predict]\n",
    "    data_re06 = [int(x) for x in HSZ1_Predict]\n",
    "    data_re07 = [int(x) for x in ZMI_Predict]\n",
    "    data_re08 = [int(x) for x in TXG_Predict]\n",
    "    data_re09 = [int(x) for x in CHW_Predict]\n",
    "    data_re10 = [int(x) for x in NTC_Predict]\n",
    "    data_re11 = [int(x) for x in YUN_Predict]\n",
    "    data_re12 = [int(x) for x in CYI0_Predict]\n",
    "    data_re13 = [int(x) for x in CYI1_Predict]\n",
    "    data_re14 = [int(x) for x in TNN_Predict]\n",
    "    data_re15 = [int(x) for x in KHH_Predict]\n",
    "    data_re16 = [int(x) for x in PIF_Predict]\n",
    "    data_re17 = [int(x) for x in ILA_Predict]\n",
    "    data_re18 = [int(x) for x in HUN_Predict]\n",
    "    data_re19 = [int(x) for x in TTT_Predict]\n",
    "    data_re20 = [int(x) for x in PEH_Predict]\n",
    "    data_re21 = [int(x) for x in KNH_Predict]\n",
    "    data_re22 = [int(x) for x in LNN_Predict]\n",
    "\n",
    "\n",
    "    # 全國人數加總list\n",
    "    data_all = []\n",
    "    \n",
    "    for i in range(len(data_re09)): \n",
    "        total = (int(data_re01[i]) + int(data_re02[i]) + int(data_re03[i]) + int(data_re04[i]) + \n",
    "                 int(data_re05[i]) + int(data_re06[i]) + int(data_re07[i]) + int(data_re08[i]) + \n",
    "                 int(data_re09[i]) + int(data_re10[i]) + int(data_re11[i]) + int(data_re12[i]) + \n",
    "                 int(data_re13[i]) + int(data_re14[i]) + int(data_re15[i]) + int(data_re16[i]) + \n",
    "                 int(data_re17[i]) + int(data_re18[i]) + int(data_re19[i]) + int(data_re20[i]) + \n",
    "                 int(data_re21[i]) + int(data_re22[i]))\n",
    "        #print(total)\n",
    "        data_all.append(total)\n",
    "        \n",
    "    #print(data_all)\n",
    "    # 日期最後一天的確診人數\n",
    "    today_data = data_all[-1]\n",
    "    data_KEL = data_re01[-1]\n",
    "    data_NTPC = data_re02[-1]\n",
    "    data_TPE = data_re03[-1]\n",
    "    data_TYN = data_re04[-1]\n",
    "    data_HSZ0 = data_re05[-1]\n",
    "    data_HSZ1 = data_re06[-1]\n",
    "    data_ZMI = data_re07[-1]\n",
    "    data_TXG = data_re08[-1]\n",
    "    data_CHW = data_re09[-1]\n",
    "    data_NTC = data_re10[-1]\n",
    "    data_YUN = data_re11[-1]\n",
    "    data_CYI0 = data_re12[-1]\n",
    "    data_CYI1 = data_re13[-1]\n",
    "    data_TNN = data_re14[-1]\n",
    "    data_KHH = data_re15[-1]\n",
    "    data_PIF = data_re16[-1]\n",
    "    data_ILA = data_re17[-1]\n",
    "    data_HUN = data_re18[-1]\n",
    "    data_TTT = data_re19[-1]\n",
    "    data_PEH = data_re20[-1]\n",
    "    data_KNH = data_re21[-1]\n",
    "    data_LNN = data_re22[-1]\n",
    "    \n",
    "        \n",
    "    # 合併list，全部日期 + 全國確診人數\n",
    "    list_all = dict(zip(date_all, data_all))\n",
    "\n",
    "\n",
    "    return render_template(\"third_web.html\", **locals())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('####  Flask Start... ####')\n",
    "    #app.debug = True\n",
    "    #app.use_reloader=False\n",
    "    app.run(host='0.0.0.0')\n",
    "    #app.run()\n",
    "    #db.close() #關閉連線"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
